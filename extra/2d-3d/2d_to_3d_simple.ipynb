{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sleap as slp\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRIORITIZE_USER_LABELED = True\n",
    "ONLY_KEEP_COMPLETE = True\n",
    "\n",
    "READ_SWING_STANCE = True\n",
    "\n",
    "z_shift = 200\n",
    "FPS = 120\n",
    "\n",
    "DEBUG_PLOT = False\n",
    "VISUALIZE_3D = True\n",
    "VALIDATE = True\n",
    "if DEBUG_PLOT:\n",
    "    import matplotlib.pyplot as plt\n",
    "if VISUALIZE_3D:\n",
    "    if not DEBUG_PLOT:\n",
    "        import matplotlib.pyplot as plt\n",
    "    colors_dict = {\n",
    "        \"RF\": (0.0, 0.0, 1.0),\n",
    "        \"RM\": (0.0, 0.0, 0.75),\n",
    "        \"RH\": (0.0, 0.0, 0.5),\n",
    "        \"LF\": (1.0, 0.0, 0.0),\n",
    "        \"LM\": (0.75, 0.0, 0.0),\n",
    "        \"LH\": (0.5, 0.0, 0.0),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_same_videos(filev, files):\n",
    "    \"\"\"\n",
    "    Check if the video in filev is the same as the video in files\n",
    "    \"\"\"\n",
    "    assert len(filev.videos) == len(files.videos), \"Number of videos is not the same\"\n",
    "    for vidv, vids in zip(filev.videos, files.videos):\n",
    "        assert vidv.filename == vids.filename, \"Videos names are not the same\"\n",
    "        assert (\n",
    "            vidv.num_frames == vids.num_frames\n",
    "        ), \"Videos have different number of frames\"\n",
    "        random_frame_id = np.random.randint(0, vidv.num_frames)\n",
    "        framev_rand = vidv.get_frame(random_frame_id)\n",
    "        frames_rand = vids.get_frame(random_frame_id)\n",
    "        assert np.all(\n",
    "            framev_rand == frames_rand\n",
    "        ), f\"Random frame {random_frame_id} is not the same in both files\"\n",
    "\n",
    "\n",
    "def get_video_vid_perp_dim(filev):\n",
    "    \"\"\"\n",
    "    Get the width of the video in filev\n",
    "    \"\"\"\n",
    "    vids_perp_dim = []\n",
    "    for vidv in filev.videos:\n",
    "        vids_perp_dim.append(vidv.height)\n",
    "    return vids_perp_dim\n",
    "\n",
    "\n",
    "def build_final_df(filev):\n",
    "    \"\"\"\n",
    "    Build the final dataframe from the ventral view file\n",
    "    \"\"\"\n",
    "    assert (\n",
    "        len(filev.skeletons) == 1\n",
    "    ), \"More than one skeleton in the file do not know what to do YET\"\n",
    "    columns = [\"frame_idx\", \"video_id\"]\n",
    "    for node in filev.skeletons[0].nodes:\n",
    "        columns.append(node.name + \"_x\")\n",
    "        columns.append(node.name + \"_y\")\n",
    "        columns.append(node.name + \"_z\")\n",
    "\n",
    "    return pd.DataFrame(columns=columns)\n",
    "\n",
    "\n",
    "def get_instance_properties(sframe, vid_perp_dim):\n",
    "    \"\"\"\n",
    "    Check wether the frame has the two side views labeled and wether frames are user labeled or not\n",
    "    \"\"\"\n",
    "    inst_user_labeled = np.zeros(len(sframe.instances), dtype=bool)\n",
    "    is_inf_prism = np.zeros(len(sframe.instances), dtype=bool)\n",
    "    is_sup_prism = np.zeros(len(sframe.instances), dtype=bool)\n",
    "    for i, instance in enumerate(sframe.instances):\n",
    "        median_perp_pos = np.nanmedian(instance.numpy()[:, 1])\n",
    "        # the origin is at the top left\n",
    "        if median_perp_pos < vid_perp_dim / 2:\n",
    "            is_sup_prism[i] = True\n",
    "        else:\n",
    "            is_inf_prism[i] = True\n",
    "        if instance in sframe.user_instances:\n",
    "            inst_user_labeled[i] = True\n",
    "    # if the image is horizontal, the sup prism is the bottom one\n",
    "    return is_inf_prism, is_sup_prism, inst_user_labeled\n",
    "\n",
    "\n",
    "def select(list, bool_list):\n",
    "    return [l for l, b in zip(list, bool_list) if b]\n",
    "\n",
    "\n",
    "def get_best_side_instances(instances, is_inf_prism, is_sup_prism, inst_user_labeled):\n",
    "    \"\"\"\n",
    "    Get the best side labels\n",
    "    We take a right and left prism instance with a priority for user labeled instances if PRIORITIZE_USER_LABELED is True\n",
    "    If multiple predictions on the same side take the one with the less nans\n",
    "\n",
    "    NEED TO REWRITE TO MAKE IT FASTER WITHOUT USING THE SELECT FUNCTION\n",
    "    \"\"\"\n",
    "    inf_prism_inst = None\n",
    "    sup_prism_inst = None\n",
    "\n",
    "    assert np.any(is_inf_prism) or np.any(\n",
    "        is_sup_prism\n",
    "    ), \"No prism instance found (This should have been caught earlier), {}, {}, {}\".format(\n",
    "        is_inf_prism, is_sup_prism, inst_user_labeled\n",
    "    )\n",
    "\n",
    "    if PRIORITIZE_USER_LABELED:\n",
    "        inf_user_labeled = np.logical_and(inst_user_labeled, is_inf_prism)\n",
    "        sup_user_labeled = np.logical_and(inst_user_labeled, is_sup_prism)\n",
    "        if np.any(inf_user_labeled):\n",
    "            inf_prism_inst = get_lessnan_inst(select(instances, inf_user_labeled))\n",
    "        else:\n",
    "            inf_prism_inst = get_lessnan_inst(select(instances, is_inf_prism))\n",
    "        if np.any(sup_user_labeled):\n",
    "            sup_prism_inst = get_lessnan_inst(select(instances, sup_user_labeled))\n",
    "        else:\n",
    "            sup_prism_inst = get_lessnan_inst(select(instances, is_sup_prism))\n",
    "    else:\n",
    "        inf_prism_inst = get_lessnan_inst(select(instances, is_inf_prism))\n",
    "        sup_prism_inst = get_lessnan_inst(select(instances, is_sup_prism))\n",
    "\n",
    "    assert (\n",
    "        inf_prism_inst is not None or sup_prism_inst is not None\n",
    "    ), \"No prism instance selected, {}, {}\".format(inf_prism_inst, sup_prism_inst)\n",
    "    return inf_prism_inst, sup_prism_inst\n",
    "\n",
    "\n",
    "def get_v_instance(vframe):\n",
    "    \"\"\"\n",
    "    Get the ventral view instance\n",
    "    \"\"\"\n",
    "    if PRIORITIZE_USER_LABELED and len(vframe.user_instances) > 0:\n",
    "        v_inst = get_lessnan_inst(vframe.user_instances)\n",
    "    else:\n",
    "        v_inst = get_lessnan_inst(vframe.instances)\n",
    "    return v_inst\n",
    "\n",
    "\n",
    "def get_lessnan_inst(instances):\n",
    "    \"\"\"\n",
    "    Compare the instances and return the one with the less nans\n",
    "    \"\"\"\n",
    "    return min(instances, key=lambda x: np.sum(np.isnan(x.numpy())))\n",
    "\n",
    "\n",
    "def triangulate_instances(v_inst, infp_inst, supp_inst):\n",
    "    n_points = len(v_inst.skeleton.nodes)\n",
    "    n_coords = n_points * 3\n",
    "    point_names = np.empty(n_coords, \"object\")\n",
    "    points_3d = np.zeros(n_coords)\n",
    "\n",
    "    x_alignement = np.zeros(n_points)\n",
    "    x_alignement_nodes = np.empty(n_points, \"object\")\n",
    "\n",
    "    infp_nodes = [node.name for node in infp_inst.skeleton.nodes]\n",
    "    supp_nodes = [node.name for node in supp_inst.skeleton.nodes]\n",
    "\n",
    "    assert infp_nodes == supp_nodes, \"Left and right prism do not have the same nodes\"\n",
    "    v_nodes = [node.name for node in v_inst.skeleton.nodes]\n",
    "    s_nodes = infp_nodes\n",
    "\n",
    "    v_points = v_inst.points_array\n",
    "    infp_points = infp_inst.points_array\n",
    "    supp_points = supp_inst.points_array\n",
    "\n",
    "    # Define wether left or right prism has the left or right side of the fly\n",
    "    head_idx = v_nodes.index(\"He\")\n",
    "    abdomen_idx = v_nodes.index(\"Abd\")\n",
    "    v_th_idx = v_nodes.index(\"Th\")\n",
    "    s_th_idx = s_nodes.index(\"Th\")\n",
    "\n",
    "    # Define the coordinate in 2D defining the local frame of the fly\n",
    "    # if the image is horiziontal:\n",
    "    # x for the fly (anteroposterior) is along the images x axis\n",
    "    # y for the fly (mediolateral) is along the images y axis\n",
    "    # z for the fly (dorsoventral) is along the images y axis\n",
    "    s_corresp = {\"z\": 1, \"x\": 0, \"y\": None}\n",
    "    v_corresp = {\"z\": None, \"x\": 0, \"y\": 1}\n",
    "\n",
    "    # Now lets note that the image reference frame is the following:\n",
    "    # image x is horizontal and positive to the right\n",
    "    # image y is vertical and positive to the bottom\n",
    "\n",
    "    # In order to merge side views and ventral views, we need to know wehter the fly is looking in one direction or the other\n",
    "    # If the image is vertical when the fly looks down, the left side of the fly is on the left of the image\n",
    "    # In this case the fly looks downward if the head is below the abdomen (e.g as top left corner is the origin head>abdomen)\n",
    "\n",
    "    # If horizontal left of the fly is in the infprism if the fly is looking to the right (e.g as top left corner is the origin head<abdomen)\n",
    "    fleft_in_inf = (\n",
    "        v_points[head_idx, v_corresp[\"x\"]] > v_points[abdomen_idx, v_corresp[\"x\"]]\n",
    "    )\n",
    "\n",
    "    # Now lets define the fly's local frame\n",
    "    # x is the anteroposterior axis and is positive toward the head\n",
    "    # y is the mediolateral axis and is positive toward the left of the fly (three fingers rule)\n",
    "    # z is the dorsoventral axis and is positive toward the top\n",
    "    # The origin is 200 pixels under the thorax (see main for the zshift)\n",
    "\n",
    "    # Reverse the dorsoventral axis for the infp_points (as we want zClaw - zAbd to be negative)\n",
    "    infp_points[:, s_corresp[\"z\"]] = -infp_points[:, s_corresp[\"z\"]]\n",
    "\n",
    "    # if the fly is looking to the left, we need to rotate arround the abdomen (invert x and y) to get the positive x axis pointing toward the head\n",
    "    if not fleft_in_inf:\n",
    "        infp_points[:, s_corresp[\"x\"]] *= -1\n",
    "        supp_points[:, s_corresp[\"x\"]] *= -1\n",
    "        v_points *= -1\n",
    "\n",
    "    leftfly_points = supp_points.copy()\n",
    "    rightfly_points = infp_points.copy()\n",
    "    if fleft_in_inf:\n",
    "        leftfly_points = infp_points.copy()\n",
    "        rightfly_points = supp_points.copy()\n",
    "\n",
    "    # Now triangulate\n",
    "    for i, node in enumerate(v_nodes):\n",
    "        # give a look at thre alignement of the x coordinates\n",
    "        if VALIDATE:\n",
    "            x_alignement_nodes[i] = node + \"_x\"\n",
    "            if node in [\"Th\", \"Abd\", \"He\"]:\n",
    "                s_id = s_nodes.index(node)\n",
    "                x_alignement[i] = np.max(\n",
    "                    np.abs(\n",
    "                        [\n",
    "                            v_points[i, v_corresp[\"x\"]]\n",
    "                            - leftfly_points[s_id, s_corresp[\"x\"]],\n",
    "                            v_points[i, v_corresp[\"x\"]]\n",
    "                            - rightfly_points[s_id, s_corresp[\"x\"]],\n",
    "                        ]\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                s_id = s_nodes.index(node[1:])\n",
    "                if node[0] == \"R\":\n",
    "                    x_alignement[i] = np.abs(\n",
    "                        v_points[i, v_corresp[\"x\"]]\n",
    "                        - rightfly_points[s_id, s_corresp[\"x\"]]\n",
    "                    )\n",
    "                elif node[0] == \"L\":\n",
    "                    x_alignement[i] = np.abs(\n",
    "                        v_points[i, v_corresp[\"x\"]]\n",
    "                        - leftfly_points[s_id, s_corresp[\"x\"]]\n",
    "                    )\n",
    "\n",
    "        for j, coord in enumerate([\"x\", \"y\", \"z\"]):\n",
    "            point_names[i * 3 + j] = node + \"_\" + coord\n",
    "            if coord in [\"x\", \"y\"]:\n",
    "                points_3d[i * 3 + j] = (\n",
    "                    v_points[i, v_corresp[coord]] - v_points[v_th_idx, v_corresp[coord]]\n",
    "                )\n",
    "            else:\n",
    "                if node in [\"Th\", \"Abd\", \"He\"]:\n",
    "                    s_id = s_nodes.index(node)\n",
    "                    # Look at the distance to the thorax\n",
    "                    points_3d[i * 3 + j] = np.mean(\n",
    "                        [\n",
    "                            leftfly_points[s_id, s_corresp[coord]]\n",
    "                            - leftfly_points[s_th_idx, s_corresp[coord]],\n",
    "                            (\n",
    "                                rightfly_points[s_id, s_corresp[coord]]\n",
    "                                - rightfly_points[s_th_idx, s_corresp[coord]]\n",
    "                            ),\n",
    "                        ]\n",
    "                    )\n",
    "                else:\n",
    "                    s_id = s_nodes.index(node[1:])\n",
    "                    if node[0] == \"R\":\n",
    "                        points_3d[i * 3 + j] = (\n",
    "                            rightfly_points[s_id, s_corresp[coord]]\n",
    "                            - rightfly_points[s_th_idx, s_corresp[coord]]\n",
    "                        )\n",
    "                    elif node[0] == \"L\":\n",
    "                        points_3d[i * 3 + j] = (\n",
    "                            leftfly_points[s_id, s_corresp[coord]]\n",
    "                            - leftfly_points[s_th_idx, s_corresp[coord]]\n",
    "                        )\n",
    "                    else:\n",
    "                        raise ValueError(\"Node name not recognized\")\n",
    "\n",
    "    return pd.DataFrame(columns=point_names, data=[points_3d]), pd.DataFrame(\n",
    "        columns=x_alignement_nodes, data=[x_alignement]\n",
    "    )\n",
    "\n",
    "\n",
    "def make_2dproj_video(df, skeleton, output_folder, ax_limits):\n",
    "    output_2d_path = output_folder / \"2d_proj\"\n",
    "    output_2d_path.mkdir(exist_ok=True)\n",
    "\n",
    "    for frame_idx in range(len(df)):\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        for edge in skeleton.edges:\n",
    "            start_pts = edge[0].name\n",
    "            end_pts = edge[1].name\n",
    "\n",
    "            edge_leg = start_pts[:2]\n",
    "            if edge_leg in colors_dict.keys():\n",
    "                color = colors_dict[edge_leg]\n",
    "            else:\n",
    "                color = \"black\"\n",
    "\n",
    "            axs[0].plot(\n",
    "                [df[f\"{start_pts}_x\"][frame_idx], df[f\"{end_pts}_x\"][frame_idx]],\n",
    "                [df[f\"{start_pts}_y\"][frame_idx], df[f\"{end_pts}_y\"][frame_idx]],\n",
    "                color=color,\n",
    "            )\n",
    "            axs[1].plot(\n",
    "                [df[f\"{start_pts}_x\"][frame_idx], df[f\"{end_pts}_x\"][frame_idx]],\n",
    "                [df[f\"{start_pts}_z\"][frame_idx], df[f\"{end_pts}_z\"][frame_idx]],\n",
    "                color=color,\n",
    "            )\n",
    "            axs[2].plot(\n",
    "                [df[f\"{start_pts}_y\"][frame_idx], df[f\"{end_pts}_y\"][frame_idx]],\n",
    "                [df[f\"{start_pts}_z\"][frame_idx], df[f\"{end_pts}_z\"][frame_idx]],\n",
    "                color=color,\n",
    "            )\n",
    "\n",
    "            if \"Claw\" in end_pts:\n",
    "                axs[0].scatter(\n",
    "                    df[f\"{end_pts}_x\"][frame_idx],\n",
    "                    df[f\"{end_pts}_y\"][frame_idx],\n",
    "                    color=color,\n",
    "                    marker=\"x\",\n",
    "                    label=end_pts[:2],\n",
    "                )\n",
    "                axs[1].scatter(\n",
    "                    df[f\"{end_pts}_x\"][frame_idx],\n",
    "                    df[f\"{end_pts}_z\"][frame_idx],\n",
    "                    color=color,\n",
    "                    marker=\"x\",\n",
    "                    label=end_pts[:2],\n",
    "                )\n",
    "                axs[2].scatter(\n",
    "                    df[f\"{end_pts}_y\"][frame_idx],\n",
    "                    df[f\"{end_pts}_z\"][frame_idx],\n",
    "                    color=color,\n",
    "                    marker=\"x\",\n",
    "                    label=end_pts[:2],\n",
    "                )\n",
    "\n",
    "        x_limits = [[-200, 200], [-200, 200], [-200, 200]]\n",
    "        y_limits = [[-200, 200], [-50, 350], [-50, 350]]\n",
    "        x_labels = [\"x\", \"x\", \"y\"]\n",
    "        y_labels = [\"y\", \"z\", \"z\"]\n",
    "\n",
    "        for i in range(3):\n",
    "            axs[i].legend(loc=\"upper left\")\n",
    "            axs[i].set_xlim(x_limits[i])\n",
    "            axs[i].set_ylim(y_limits[i])\n",
    "            axs[i].set_xlabel(x_labels[i])\n",
    "            axs[i].set_ylabel(y_labels[i])\n",
    "\n",
    "        \"\"\"for i,ax in enumerate(axs):\n",
    "            ax.set_xlim(ax_limits[0])\n",
    "            #ax.set_aspect('equal', adjustable='box')\n",
    "            if i == 0:\n",
    "                ax.set_ylim(ax_limits[1])\n",
    "            else:\n",
    "                #projection looks at y\n",
    "                ax.set_ylim(ax_limits[2])\"\"\"\n",
    "\n",
    "        # Save to temporary folder\n",
    "        plt.savefig(output_2d_path / f\"{frame_idx}.png\")\n",
    "        plt.close()\n",
    "\n",
    "    # Use ffmpeg to create video\n",
    "    os.system(\n",
    "        f\"ffmpeg -y -framerate 60 -i {str(output_2d_path)}/%d.png -c:v libx264 -profile:v high -crf 20 -pix_fmt yuv420p {str(output_2d_path)}/pose_vid.mp4\"\n",
    "    )\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def make_3d_video(df, skeleton, output_folder, ax_limits, azimuth=45, elevation=15):\n",
    "    \"\"\"\n",
    "    The same as for 2d video but in 3d but generates a 3d plot using projection='3d'\n",
    "    \"\"\"\n",
    "\n",
    "    output_3d_path = output_folder / \"3d_proj\"\n",
    "    output_3d_path.mkdir(exist_ok=True)\n",
    "\n",
    "    for frame_idx in range(len(df)):\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        fig.patch.set_facecolor(\"black\")\n",
    "        ax = fig.add_subplot(111, projection=\"3d\")\n",
    "        # Set the axes background color to black\n",
    "        ax.set_facecolor(\"black\")\n",
    "        ax.view_init(azim=azimuth, elev=elevation)\n",
    "        ax.set_zlim(ax_limits[0])\n",
    "        ax.set_ylim(ax_limits[1])\n",
    "        ax.set_xlim(ax_limits[2])\n",
    "\n",
    "        for edge in skeleton.edges:\n",
    "            start_pts = edge[0].name\n",
    "            end_pts = edge[1].name\n",
    "\n",
    "            edge_leg = start_pts[:2]\n",
    "            if edge_leg in colors_dict.keys():\n",
    "                color = colors_dict[edge_leg]\n",
    "            else:\n",
    "                color = \"black\"\n",
    "\n",
    "            ax.plot(\n",
    "                [df[f\"{start_pts}_x\"][frame_idx], df[f\"{end_pts}_x\"][frame_idx]],\n",
    "                [df[f\"{start_pts}_y\"][frame_idx], df[f\"{end_pts}_y\"][frame_idx]],\n",
    "                [df[f\"{start_pts}_z\"][frame_idx], df[f\"{end_pts}_z\"][frame_idx]],\n",
    "                color=color,\n",
    "            )\n",
    "            if \"Claw\" in end_pts:\n",
    "                ax.scatter(\n",
    "                    df[f\"{end_pts}_x\"][frame_idx],\n",
    "                    df[f\"{end_pts}_y\"][frame_idx],\n",
    "                    df[f\"{end_pts}_z\"][frame_idx],\n",
    "                    color=color,\n",
    "                    marker=\"x\",\n",
    "                    label=end_pts[:2],\n",
    "                )\n",
    "\n",
    "        # set the legend in the 3d axis\n",
    "        ax.legend(\n",
    "            loc=\"upper left\", bbox_to_anchor=(0.1, 0.7), fontsize=15\n",
    "        )  # Specific coordinates in axes space\n",
    "        # set the axis limits -200 200 for x and y and 0 250 for z\n",
    "        ax.set_xlim([-150, 150])\n",
    "        ax.set_ylim([-150, 150])\n",
    "        ax.set_zlim([-50, 250])\n",
    "        ax.set_xlabel(\"x\")\n",
    "        ax.set_ylabel(\"y\")\n",
    "        ax.set_zlabel(\"z\")\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_zticklabels([])\n",
    "\n",
    "        plt.tight_layout()\n",
    "        # Save to temporary folder\n",
    "        plt.savefig(output_3d_path / f\"{frame_idx}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "    # Use ffmpeg to create video\n",
    "    os.system(\n",
    "        f\"ffmpeg -y -framerate 60 -i {str(output_3d_path)}/%d.png -c:v libx264 -profile:v high -crf 20 -pix_fmt yuv420p {str(output_3d_path)}/pose_vid.mp4\"\n",
    "    )\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def triangulate(ventral_labels, sides_labels, vids_perp_dim):\n",
    "    \"\"\"\n",
    "    Does all the triangulation work\n",
    "    \"\"\"\n",
    "    # create the final dataframe\n",
    "    # df = build_final_df(ventral_labels)\n",
    "    frame_arr = []\n",
    "    alignement_arr = []\n",
    "    frame_indexes = []\n",
    "    slp_instances = []\n",
    "    # iterate over labeled frames\n",
    "\n",
    "    for vframe in sorted(ventral_labels, key=lambda x: x.frame_idx):\n",
    "        if len(vframe.instances) < 1:\n",
    "            # This should not have to be but the file might be weird for ventral\n",
    "            continue\n",
    "        assert (\n",
    "            len(vframe.instances) > 0\n",
    "        ), \"No instance found in ventral frame with index {}\".format(vframe.frame_idx)\n",
    "        # Check wether frame is present in the side view\n",
    "        video_id = ventral_labels.videos.index(vframe.video)\n",
    "        sframe = sides_labels.find(\n",
    "            video=sides_labels.videos[video_id], frame_idx=vframe.frame_idx\n",
    "        )\n",
    "        assert len(sframe) <= 1, \"More than one side view frame found: {}\".format(\n",
    "            sframe\n",
    "        )\n",
    "        sframe = sframe[0]\n",
    "        if len(sframe.instances) < 2:\n",
    "            print(\n",
    "                \"REJECTED: Ventral frame with index {} had less than two side views\".format(\n",
    "                    vframe.frame_idx\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            is_inf_prism, is_sup_prism, inst_user_labeled = get_instance_properties(\n",
    "                sframe, vids_perp_dim[video_id]\n",
    "            )\n",
    "            assert not np.any(\n",
    "                np.logical_and(is_inf_prism, is_sup_prism)\n",
    "            ), \"Frame with index {} has both left and right prism labeled.\".format(\n",
    "                sframe.frame_idx\n",
    "            )\n",
    "            if np.all(is_inf_prism):\n",
    "                print(\n",
    "                    \"REJECTED: Side frame with index {} has only top prism labeled.\".format(\n",
    "                        sframe.frame_idx\n",
    "                    )\n",
    "                )\n",
    "                continue\n",
    "            elif np.all(is_sup_prism):\n",
    "                print(\n",
    "                    \"REJECTED: Side frame with index {} has only bottom prism labeled.\".format(\n",
    "                        sframe.frame_idx\n",
    "                    )\n",
    "                )\n",
    "                continue\n",
    "            else:\n",
    "                frame_indexes.append(vframe.frame_idx)\n",
    "                inf_prism_inst, sup_prism_inst = get_best_side_instances(\n",
    "                    sframe.instances, is_inf_prism, is_sup_prism, inst_user_labeled\n",
    "                )\n",
    "            # Get the ventral view instance\n",
    "            v_inst = get_v_instance(vframe)\n",
    "            if ONLY_KEEP_COMPLETE:\n",
    "                for k, inst in enumerate([v_inst, inf_prism_inst, sup_prism_inst]):\n",
    "                    if np.sum(np.isnan(inst.numpy())) > 0:\n",
    "                        break\n",
    "                if k < 2:\n",
    "                    print(\n",
    "                        \"REJECTED: Frame with index {} has incomplete instance.\".format(\n",
    "                            sframe.frame_idx\n",
    "                        )\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "            slp_instances.append([v_inst, inf_prism_inst, sup_prism_inst])\n",
    "            triangulated_serie, alignement_serie = triangulate_instances(\n",
    "                v_inst, inf_prism_inst, sup_prism_inst\n",
    "            )\n",
    "            triangulated_serie[\"frame_idx\"] = vframe.frame_idx\n",
    "            triangulated_serie[\"video_id\"] = video_id\n",
    "            frame_arr.append(triangulated_serie)\n",
    "            alignement_serie[\"frame_idx\"] = vframe.frame_idx\n",
    "            alignement_serie[\"video_id\"] = video_id\n",
    "            alignement_arr.append(alignement_serie)\n",
    "            # df = pd.concat([df, triangulated_serie], axis=0)\n",
    "\n",
    "    return (\n",
    "        pd.concat(frame_arr, axis=0, ignore_index=True),\n",
    "        pd.concat(alignement_arr, axis=0, ignore_index=True),\n",
    "        frame_indexes,\n",
    "        slp_instances,\n",
    "    )\n",
    "\n",
    "\n",
    "def reveal_length_outliers(df, skel):\n",
    "    edge_lengths = []\n",
    "    edge_names = []\n",
    "    for edge in skel.edges:\n",
    "        start_pts = edge[0].name\n",
    "        end_pts = edge[1].name\n",
    "        edge_names.append(start_pts.replace(\"-\", \"\") + \"-\" + end_pts.replace(\"-\", \"\"))\n",
    "        edge_lengths.append(\n",
    "            np.linalg.norm(\n",
    "                df[[f\"{start_pts}_x\", f\"{start_pts}_y\", f\"{start_pts}_z\"]].values\n",
    "                - df[[f\"{end_pts}_x\", f\"{end_pts}_y\", f\"{end_pts}_z\"]].values,\n",
    "                axis=1,\n",
    "            )\n",
    "        )\n",
    "    # Find outliers using the interquartile range\n",
    "    edge_lengths = np.array(edge_lengths)\n",
    "    edge_names = np.array(edge_names)\n",
    "    q1 = np.quantile(edge_lengths, 0.25, axis=1)\n",
    "    q3 = np.quantile(edge_lengths, 0.75, axis=1)\n",
    "    iqr = q3 - q1\n",
    "    lower_bounds = q1 - (1.5 * iqr)\n",
    "    upper_bounds = q3 + (1.5 * iqr)\n",
    "    frame_ids = df[\"frame_idx\"].values\n",
    "    shorter_than_lower_bound = np.where(edge_lengths < lower_bounds[:, None])\n",
    "    longer_than_upper_bound = np.where(edge_lengths > upper_bounds[:, None])\n",
    "    print(\"Revealing length outliers:\")\n",
    "    for edge_loc, frame_loc in zip(*shorter_than_lower_bound):\n",
    "        edge_name = edge_names[edge_loc]\n",
    "        frame_id = frame_ids[frame_loc]\n",
    "        lower_bound = lower_bounds[edge_loc]\n",
    "        edge_length = edge_lengths[edge_loc, frame_loc]\n",
    "        print(\n",
    "            \"Edge {} is shorter than lower bound at frame {} (length: {:.2f} lower bound: {:.2f})\".format(\n",
    "                edge_name, frame_id, edge_length, lower_bound\n",
    "            )\n",
    "        )\n",
    "    for edge_loc, frame_loc in zip(*longer_than_upper_bound):\n",
    "        edge_name = edge_names[edge_loc]\n",
    "        frame_id = frame_ids[frame_loc]\n",
    "        upper_bound = upper_bounds[edge_loc]\n",
    "        edge_length = edge_lengths[edge_loc, frame_loc]\n",
    "        print(\n",
    "            \"Edge {} is longer than upper bound at frame {} (length: {:.2f} upper bound: {:.2f})\".format(\n",
    "                edge_name, frame_id, edge_length, upper_bound\n",
    "            )\n",
    "        )\n",
    "    outlier_frame_ids = np.unique(\n",
    "        np.concatenate(\n",
    "            [\n",
    "                frame_ids[shorter_than_lower_bound[1]],\n",
    "                frame_ids[longer_than_upper_bound[1]],\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return outlier_frame_ids\n",
    "\n",
    "\n",
    "def reveal_alignement_issues(alignement_arr, pixel_thr=10):\n",
    "    \"\"\"\n",
    "    Reveal alignement issues (side views and ventral views x coords are not aligned)\n",
    "    \"\"\"\n",
    "    alignement_vals = alignement_arr.loc[\n",
    "        :, ~alignement_arr.columns.isin([\"frame_idx\", \"video_id\"])\n",
    "    ].values\n",
    "    # get all frames and points with a distance of more than pixel_thr distance\n",
    "    point_locs = np.where(alignement_vals > pixel_thr)\n",
    "    for frame_loc, node_loc in zip(*point_locs):\n",
    "        frame_id = alignement_arr[\"frame_idx\"].values[frame_loc]\n",
    "        node_name = alignement_arr.columns[node_loc]\n",
    "        distance = alignement_arr.iloc[frame_loc, node_loc]\n",
    "        print(\n",
    "            \"Frame {} has an alignement issue for node {} (distance: {:.2f})\".format(\n",
    "                frame_id, node_name, distance\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return np.unique(alignement_arr[\"frame_idx\"].values[point_locs[0]])\n",
    "\n",
    "\n",
    "def read_swing_stance_file(file_path):\n",
    "    \"\"\"\n",
    "    Read the swing stance file\n",
    "    It should be formatted as follows:\n",
    "\n",
    "    Start 0\n",
    "    End 1000\n",
    "\n",
    "    RF\n",
    "    swing 0 21 32\n",
    "    stance 5 28 39\n",
    "\n",
    "    RM\n",
    "    swing 0 17 25\n",
    "    stance 5 20 30\n",
    "    ect..\n",
    "\n",
    "    Number are the indexes of swing start and stance start\n",
    "\n",
    "    We create a dict with the following structure:\n",
    "    {RF:{swing:[0, 21, 32], stance:[5, 28, 39]},\n",
    "     RM:{swing:[0, 17, 25], stance:[5, 20, 30]},\n",
    "     ect...}\n",
    "    \"\"\"\n",
    "    start, end = None, None\n",
    "    swing_stance_dict = {}\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.strip()\n",
    "            if line.startswith(\"Start\"):\n",
    "                start = int(line.split(\" \")[1])\n",
    "            if line.startswith(\"End\"):\n",
    "                end = int(line.split(\" \")[1])\n",
    "            if line in [\"RF\", \"RM\", \"RH\", \"LF\", \"LM\", \"LH\"]:\n",
    "                assert (\n",
    "                    start is not None and end is not None\n",
    "                ), \"Start and end not defined\"\n",
    "                leg = line\n",
    "                swing_stance_dict[leg] = {}\n",
    "            if \"swing\" in line or \"stance\" in line:\n",
    "                phase = line.split(\" \")[0]\n",
    "                indexes = np.array(line.split(\" \")[1:]).astype(int)\n",
    "                assert np.all(indexes >= start - 1) and np.all(\n",
    "                    indexes <= end + 1\n",
    "                ), \"Indexes not in range\"\n",
    "                indexes -= start\n",
    "                if phase == \"swing\":\n",
    "                    # the frames in the file are the ones were the first elevation\n",
    "                    # is observed but really the swing starts inbeetween the two frames\n",
    "                    # This gives some margin for the adhesion\n",
    "                    indexes -= 1\n",
    "\n",
    "                # save as integers\n",
    "                swing_stance_dict[leg][phase] = indexes / FPS\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    return swing_stance_dict\n",
    "\n",
    "\n",
    "def plot_swing_stance(df, swing_stance_dict, save_path, n_cols=2):\n",
    "    \"\"\"\n",
    "    Here the idea is to overlay the x, y and z coordinates of the tarsus of every leg and highlight the swing and stance phases\n",
    "    \"\"\"\n",
    "    legs = swing_stance_dict.keys()\n",
    "    fig, axs = plt.subplots(\n",
    "        n_cols, np.ceil(len(legs) / n_cols).astype(int), figsize=(10, 10)\n",
    "    )\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    time = np.arange(len(df)) / FPS\n",
    "\n",
    "    for i, leg in enumerate(legs):\n",
    "        swing_stance = swing_stance_dict[leg]\n",
    "        swing_starts = swing_stance[\"swing\"]\n",
    "        stance_starts = swing_stance[\"stance\"]\n",
    "        tarsus_x = df[f\"{leg}-TiTa_x\"].values\n",
    "        tarsus_y = df[f\"{leg}-TiTa_y\"].values\n",
    "        tarsus_z = df[f\"{leg}-TiTa_z\"].values\n",
    "        axs[i].plot(time, tarsus_x, label=\"x\")\n",
    "        axs[i].plot(time, tarsus_y, label=\"y\")\n",
    "        axs[i].plot(time, tarsus_z, label=\"z\")\n",
    "        axs[i].set_title(leg)\n",
    "        if swing_starts[0] > stance_starts[0]:\n",
    "            swing_starts = np.insert(swing_starts, 0, 0)\n",
    "        if stance_starts[-1] < swing_starts[-1]:\n",
    "            stance_starts = np.append(stance_starts, time[-1])\n",
    "        for k, (swing_start, stance_start) in enumerate(\n",
    "            zip(swing_starts, stance_starts)\n",
    "        ):\n",
    "            if k == 0:\n",
    "                axs[i].axvspan(\n",
    "                    swing_start, stance_start, alpha=0.2, color=\"green\", label=\"swing\"\n",
    "                )\n",
    "            else:\n",
    "                axs[i].axvspan(swing_start, stance_start, alpha=0.2, color=\"green\")\n",
    "\n",
    "        axs[i].legend()\n",
    "    return fig, axs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From 2d to 3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventral_input_file = Path(\"../data/2d_pose/best_ventral.slp\")\n",
    "sides_input_file = Path(\"../data/2d_pose/best_side.slp\")\n",
    "\n",
    "output_folder = Path(\"../data/3d_pose\")\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "# load sleap files\n",
    "ventral_labels = slp.load_file(\n",
    "    str(ventral_input_file), search_paths=\"../data/video_data/straight_walking_bout.mp4\"\n",
    ")\n",
    "sides_labels = slp.load_file(\n",
    "    str(sides_input_file), search_paths=\"../data/video_data/straight_walking_bout.mp4\"\n",
    ")\n",
    "\n",
    "# check that the video in both files is the same\n",
    "has_same_videos(ventral_labels, sides_labels)\n",
    "vids_perp_dim = get_video_vid_perp_dim(ventral_labels)\n",
    "\n",
    "df, df_alignement, used_frame_indexes, slp_instances = triangulate(\n",
    "    ventral_labels, sides_labels, vids_perp_dim\n",
    ")\n",
    "\n",
    "# shift the z axis to have positive values\n",
    "df.loc[:, df.columns.str.endswith(\"_z\")] += z_shift\n",
    "\n",
    "# save to csv\n",
    "df.to_csv(\n",
    "    output_folder\n",
    "    / \"clean_3d_{}_{}.csv\".format(ventral_input_file.stem, sides_input_file.stem)\n",
    ")\n",
    "\n",
    "if VALIDATE:\n",
    "    # reveal length outliers\n",
    "    frame_ids = reveal_length_outliers(df, ventral_labels.skeletons[0])\n",
    "    # reveal alignement issues\n",
    "    frame_ids = reveal_alignement_issues(df_alignement)\n",
    "\n",
    "if VISUALIZE_3D:\n",
    "    ax_limits = []\n",
    "    for coord in [\"z\", \"y\", \"x\"]:\n",
    "        coord_cols = df.columns.str.endswith(coord)\n",
    "        ax_limits.append(\n",
    "            [np.min(df.loc[:, coord_cols].values), np.max(df.loc[:, coord_cols].values)]\n",
    "        )\n",
    "\n",
    "    # Save the 3d plots in a folder and make a video\n",
    "    print(\"Making 2D projection video ....\")\n",
    "    make_2dproj_video(df, ventral_labels.skeletons[0], output_folder, ax_limits)\n",
    "    print(\"Making 3D video ....\")\n",
    "    make_3d_video(df, ventral_labels.skeletons[0], output_folder, ax_limits)\n",
    "\n",
    "if READ_SWING_STANCE:\n",
    "    swing_stance_file = Path(\"../data/video_data/straight_walking_bout_swingstance.txt\")\n",
    "    swing_stance_dict = read_swing_stance_file(swing_stance_file)\n",
    "    fig, axs = plot_swing_stance(df, swing_stance_dict, output_folder)\n",
    "    fig.savefig(output_folder / \"swing_stance.png\")\n",
    "    plt.close()\n",
    "    # save as .pkl file\n",
    "    with open(output_folder / \"swing_stance.pkl\", \"wb\") as f:\n",
    "        pickle.dump(swing_stance_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(output_folder / \"used_frames.txt\", used_frame_indexes, fmt=\"%i\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the sleap instances\n",
    "def plot_instance(slp_instance, ax, side=\"N\"):\n",
    "    skeleton = slp_instance.skeleton\n",
    "    points = slp_instance.numpy()\n",
    "    for node1, node2 in slp_instance.skeleton.edges:\n",
    "        n1_id = skeleton.node_names.index(node1.name)\n",
    "        n2_id = skeleton.node_names.index(node2.name)\n",
    "        if \"V\" in node1.name or \"V\" in node2.name:\n",
    "            continue\n",
    "        if side == \"N\":\n",
    "            try:\n",
    "                color = colors_dict[node1.name[:2]]\n",
    "            except:\n",
    "                color = \"white\"\n",
    "        else:\n",
    "            try:\n",
    "                color = colors_dict[side + node1.name[0]]\n",
    "            except:\n",
    "                color = \"white\"\n",
    "\n",
    "        if \"He\" in node1.name:\n",
    "            color = \"white\"\n",
    "\n",
    "        ax.plot(\n",
    "            [points[n1_id, 0], points[n2_id, 0]],\n",
    "            [points[n1_id, 1], points[n2_id, 1]],\n",
    "            color=color,\n",
    "            lw=1.0,\n",
    "        )\n",
    "\n",
    "\n",
    "labelled_frames_output = output_folder / \"labelled_frames\"\n",
    "labelled_frames_output.mkdir(exist_ok=True)\n",
    "\n",
    "for i, frame_id in enumerate(used_frame_indexes):\n",
    "    # Get the image dimensions\n",
    "    image = ventral_labels.videos[0].get_frame(frame_id)\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    # Set the figure size in inches (width, height) by converting from pixels\n",
    "    # Matplotlib's default DPI is 100, so we divide by 100 to get inches\n",
    "    dpi = 100\n",
    "    figsize = width / dpi, height / dpi\n",
    "\n",
    "    # Create the figure with the exact size of the image\n",
    "    fig, ax = plt.subplots(figsize=figsize, dpi=dpi)\n",
    "    plot_instance(\n",
    "        slp_instances[i][0],\n",
    "        ax,\n",
    "    )\n",
    "    plot_instance(slp_instances[i][1], ax, \"R\")\n",
    "    plot_instance(slp_instances[i][2], ax, \"L\")\n",
    "    ax.imshow(image, cmap=\"gray\")\n",
    "    ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(labelled_frames_output / f\"{i}.png\", bbox_inches=\"tight\", pad_inches=0)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
